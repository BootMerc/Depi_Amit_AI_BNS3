# ü§ñ Machine Learning Projects & Assignments

**Author:** *Ziad Mohamed Shaker* (BootMerc)  
**Part of:** DEPI Data Science Diploma Program

![ML Badge](https://img.shields.io/badge/Machine%20Learning-Advanced-blueviolet?style=for-the-badge)  
![Python](https://img.shields.io/badge/Python-3.8+-blue?logo=python&logoColor=white)  
![Scikit-learn](https://img.shields.io/badge/Scikit--learn-Latest-orange)  
![Status](https://img.shields.io/badge/Status-Active-brightgreen)

---

## üìã Overview

This directory contains comprehensive machine learning projects, algorithms, and assignments showcasing practical implementation of supervised learning, unsupervised learning, classification, regression, and advanced techniques.  
All projects are built with Python and leverage industry-standard libraries.

---

## üóÇÔ∏è Folder Structure & Deliverables

### üìÅ **1. Supervised Learning**
**Purpose:** Classification and regression models with labeled data  
**Key Concepts:** Decision Trees, Random Forest, Support Vector Machines (SVM), Linear/Logistic Regression  

**Deliverables:**
- `decision_tree_classifier.ipynb` - Decision tree implementation with hyperparameter tuning
- `random_forest_models.ipynb` - Ensemble methods for improved predictions
- `svm_classification.ipynb` - SVM classifier for binary/multiclass problems
- `linear_regression.ipynb` - Housing price prediction & performance metrics
- `logistic_regression.ipynb` - Binary classification with probability outputs
- `model_evaluation.py` - Cross-validation, confusion matrices, ROC curves

**Skills Demonstrated:** Model selection, hyperparameter tuning, overfitting prevention, performance metrics

---

### üìÅ **2. Unsupervised Learning**
**Purpose:** Pattern discovery and clustering without labeled data  
**Key Concepts:** K-Means, Hierarchical Clustering, PCA, Anomaly Detection  

**Deliverables:**
- `kmeans_clustering.ipynb` - Customer segmentation using K-Means
- `hierarchical_clustering.ipynb` - Dendrogram visualization & linkage methods
- `pca_dimensionality_reduction.ipynb` - Feature reduction & visualization
- `anomaly_detection.ipynb` - Outlier detection techniques
- `clustering_evaluation.py` - Silhouette score, elbow method, Davies-Bouldin index

**Skills Demonstrated:** Clustering algorithms, feature engineering, dimensionality reduction, unsupervised evaluation

---

### üìÅ **3. Neural Networks & Deep Learning**
**Purpose:** Deep learning implementations using TensorFlow/Keras  
**Key Concepts:** Feedforward NNs, Activation Functions, Backpropagation, Regularization  

**Deliverables:**
- `basic_neural_network.ipynb` - Feedforward NN from scratch
- `keras_multilayer_perceptron.ipynb` - MLP with Keras/TensorFlow
- `cnn_image_classification.ipynb` - Convolutional Neural Networks (MNIST, CIFAR-10)
- `rnn_sequence_prediction.ipynb` - Recurrent networks for time series
- `model_optimization.py` - Regularization, dropout, batch normalization

**Skills Demonstrated:** NN architecture design, activation functions, loss optimization, GPU acceleration

---

### üìÅ **4. Feature Engineering & Selection**
**Purpose:** Transforming raw data into meaningful features  
**Key Concepts:** Scaling, Normalization, Feature Selection, Encoding  

**Deliverables:**
- `feature_scaling.ipynb` - StandardScaler, MinMaxScaler comparison
- `categorical_encoding.ipynb` - One-hot encoding, label encoding
- `feature_selection.ipynb` - SelectKBest, RFE, correlation analysis
- `missing_values_handling.py` - Imputation strategies
- `feature_engineering_pipeline.py` - Automated preprocessing pipeline

**Skills Demonstrated:** Data transformation, pipeline creation, avoiding data leakage

---

### üìÅ **5. Ensemble Methods**
**Purpose:** Combining multiple models for better predictions  
**Key Concepts:** Bagging, Boosting, Stacking, Voting Classifiers  

**Deliverables:**
- `bagging_methods.ipynb` - Bagging with Decision Trees
- `boosting_algorithms.ipynb` - AdaBoost, Gradient Boosting, XGBoost
- `stacking_ensemble.ipynb` - Stacked generalization
- `voting_classifier.ipynb` - Combining diverse estimators
- `hyperparameter_grid_search.py` - GridSearchCV & RandomizedSearchCV

**Skills Demonstrated:** Ensemble theory, model stacking, hyperparameter optimization

---

### üìÅ **6. Real-World Projects**
**Purpose:** End-to-end ML projects with complete pipelines  

#### **Project 1: Housing Price Prediction**
- **Dataset:** Boston Housing / Kaggle House Prices
- **Deliverables:** Data exploration, preprocessing, multiple models, evaluation
- **File:** `housing_price_prediction_project.ipynb`

#### **Project 2: Customer Churn Prediction**
- **Dataset:** Telecom/Bank customer data
- **Deliverables:** Binary classification, SHAP interpretability, business metrics
- **File:** `customer_churn_project.ipynb`

#### **Project 3: Iris/Wine Classification**
- **Dataset:** Classic UCI datasets
- **Deliverables:** Multi-class classification, model comparison, visualization
- **File:** `flower_classification_project.ipynb`

---

### üìÅ **7. Resources & Utilities**
**Purpose:** Helper functions and configuration files  

**Deliverables:**
- `utils.py` - Preprocessing, evaluation, visualization functions
- `config.py` - Hyperparameters, paths, constants
- `requirements.txt` - Dependencies (scikit-learn, TensorFlow, XGBoost, etc.)
- `README_PROJECTS.md` - Detailed project documentation

---

## üöÄ Quick Start

### Prerequisites

